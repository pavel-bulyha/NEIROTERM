# NEIROTERM

A project for training and testing neural network models on sequences (e.g., bioinformatics, DNA/RNA classification).

## Project Structure

```
NeuralNetworks/
‚îú‚îÄ‚îÄ launcher.py
‚îú‚îÄ‚îÄ analyze_results.py
‚îú‚îÄ‚îÄ analysis_plots/
‚îÇ ‚îú‚îÄ‚îÄ balanced_acc_boxplot.png
‚îÇ ‚îú‚îÄ‚îÄ best_val_f1_boxplot.png
‚îÇ ‚îú‚îÄ‚îÄ common_hyperparams_pairplot.png
‚îÇ ‚îú‚îÄ‚îÄ common_params_parallel_coords.png
‚îÇ ‚îú‚îÄ‚îÄ full_corr_matrix.png
‚îÇ ‚îú‚îÄ‚îÄ hyperparams_pairplot.png
‚îÇ ‚îî‚îÄ‚îÄ [network]_corr_matrix.png
‚îú‚îÄ‚îÄ analysis_results/
‚îÇ ‚îú‚îÄ‚îÄ all_results_extended.csv
‚îÇ ‚îú‚îÄ‚îÄ best_per_network.csv
‚îÇ ‚îú‚îÄ‚îÄ best_per_dataset.csv
‚îÇ ‚îú‚îÄ‚îÄ overall_best.csv
‚îÇ ‚îî‚îÄ‚îÄ top_10.csv
‚îú‚îÄ‚îÄ ConvolutionalNeuralNetwork/
‚îÇ ‚îú‚îÄ‚îÄ CNN.py
‚îÇ ‚îú‚îÄ‚îÄ optuna_cnn.db
‚îÇ ‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îî‚îÄ‚îÄ saved_models/
‚îú‚îÄ‚îÄ FullyConnectedPerceptron/
‚îÇ ‚îú‚îÄ‚îÄ Perceptron.py
‚îÇ ‚îú‚îÄ‚îÄ optuna_perceptron.db
‚îÇ ‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îî‚îÄ‚îÄ saved_models/
‚îú‚îÄ‚îÄ RecurrentNeuralNetwork/
‚îÇ ‚îú‚îÄ‚îÄ RNN.py
‚îÇ ‚îú‚îÄ‚îÄ optuna_rnn.db
‚îÇ ‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îî‚îÄ‚îÄ saved_models/
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ DataUtils.py
    ‚îú‚îÄ‚îÄ WeightedBCE.py
    ‚îî‚îÄ‚îÄ registry.py
TrainData/
‚îú‚îÄ‚îÄ TrainData.7z
‚îú‚îÄ‚îÄ balance_by_ratio.py
‚îú‚îÄ‚îÄ balance_by_species.py
‚îú‚îÄ‚îÄ pad_nucleotides.py
‚îî‚îÄ‚îÄ TrainData/
    ‚îî‚îÄ‚îÄ BTFTrainData/ (folder with training data)
```

- **balance_by_ratio.py** ‚Äî script for balancing datasets by class ratio (e.g., to address class imbalance).
- **balance_by_species.py** ‚Äî script for balancing datasets by organism species (biological categories).
- **pad_nucleotides.py** ‚Äî script for padding nucleotide sequences to the same length.
- **launcher.py** ‚Äî entry point, automatically imports all models, displays available models with numbers, allows user to select specific models or run all, and runs selected models on all CSV files from the `../TrainData` folder.
- **analyze_results.py** ‚Äî advanced script for analyzing neural network training logs, supports multiple model architectures (CNN, Perceptron, RNN), generates comprehensive plots (boxplots, pairplots, correlation matrices, parallel coordinates) and detailed CSV reports with extended metrics (F1, balanced accuracy, precision, recall).
- **analysis_plots/** ‚Äî directory containing generated plots for visualizing analysis results: boxplots of balanced accuracy and F1 scores, hyperparameter pairplots, correlation matrices, and parallel coordinates for parameter analysis.
- **analysis_results/** ‚Äî directory with CSV files containing aggregated analysis data: extended results, best per network, best per dataset, overall best configuration, and top 10 results.
- **ConvolutionalNeuralNetwork/** ‚Äî implementation of Convolutional Neural Network (CNN) for sequence classification with intelligent parameter filtering and cuDNN support.
- **FullyConnectedPerceptron/** ‚Äî implementation of Multi-Layer Perceptron (MLP) model for binary classification.
- **RecurrentNeuralNetwork/** ‚Äî implementation of Recurrent Neural Network (RNN) for sequence data.
- **utils/** ‚Äî auxiliary modules:
  - `DataUtils.py` ‚Äî data preparation and encoding.
  - `WeightedBCE.py` ‚Äî weighted BCE loss function for handling imbalanced classes.
  - `registry.py` ‚Äî model registry (decorator for registering entry points).

## Adding Your Own Model

1. Create a new subfolder in the project root and add your `.py` file there.

2. Implement the launcher function, for example:
```python
from utils import register_model

@register_model("MyModel")
def MyModelRUN(data_csv: str, use_weighted_bce: bool):
    # Your training logic
    return {"accuracy": ..., "precision": ...}
```
3. launcher.py automatically imports all such functions.

## Quickstart

Minimal set of commands to run:

```bash
git clone https://github.com/pavel-bulyha/NEIROTERM.git
cd NEIROTERM
python -m venv .venv
source .venv/bin/activate      # on Unix/Mac
# or
.\.venv\Scripts\activate       # on Windows
pip install -r requirements.txt
python NeuralNetworks/launcher.py
```

## Data Preparation

### Input CSV Format and Schema

Data must be in CSV format with required columns:

- `sequence` ‚Äî string containing the sequence (e.g., nucleotide: `ATCGATCG...`)
- `class` ‚Äî integer, class label (0 or 1)

All sequences in the file must be the same length. The file must be encoded in UTF-8-BOM (with BOM) or UTF-8.

#### Example CSV file:

```
sequence,class
ATCGATCGATCG,0
GCTAGCTAGCTA,1
TTTTAAAA,0
```

CSV files are placed in the `../TrainData` folder (relative to NeuralNetworks/).

## Running

```bash
python launcher.py
```

- The script will automatically find all registered models, display them with numbers, and prompt the user to select specific models (by entering numbers separated by ';') or run all (by entering 'all').
- Selected models will be run on all CSV files (including nested ones) from the `../TrainData` folder, with two loss function modes: standard BCE and weighted BCE (`pos_weight = neg / pos`).
- For each model and each file, training logs (TSV) and weights (H5) are saved in the corresponding model folder.
- In case of errors (e.g., missing data or model), an informative message is displayed.

## Output Details

### Training Logs
- **Location**: `NeuralNetworks/[ModelName]/logs/`
- **Format**: TSV files named like `{dataset}_{mode}_{params}.tsv`
- **Contents**: Columns per epoch:
  - `epoch` ‚Äî epoch number (1-50)
  - `loss` ‚Äî loss value on training
  - `accuracy` ‚Äî accuracy on training
  - `precision` ‚Äî precision on training
  - `recall` ‚Äî recall on training
  - `neg_recall` ‚Äî recall for negative class on training
  - `val_loss` ‚Äî loss on validation
  - `val_accuracy` ‚Äî accuracy on validation
  - `val_precision` ‚Äî precision on validation
  - `val_recall` ‚Äî recall on validation
  - `val_neg_recall` ‚Äî recall for negative class on validation

  Example of first rows:
  ```
  epoch	loss	accuracy	precision	recall	neg_recall	val_loss	val_accuracy	val_precision	val_recall	val_neg_recall
  1	0.693	0.500	0.500	0.500	0.500	0.693	0.500	0.500	0.500	0.500
  2	0.690	0.525	0.525	0.525	0.525	0.690	0.525	0.525	0.525	0.525
  ...
  ```

  These logs are used by the `analyze_results.py` script to compute additional metrics (balanced accuracy, F1-score).

### Saved Models
- **Location**: `NeuralNetworks/[ModelName]/saved_models/`
- **Format**: Folders named like `{dataset}_{mode}_{params}/` containing `epoch_01.h5`, `epoch_02.h5`, ..., `epoch_50.h5`
- **Contents**: Keras weight files (.h5) for each training epoch.

### Analysis Reports
- **Location**: `NeuralNetworks/analysis_results/`
- **Files**:
  - `all_results_extended.csv` ‚Äî all results with metrics
  - `best_per_network.csv` ‚Äî best per network
  - `best_per_dataset.csv` ‚Äî best per dataset
  - `overall_best.csv` ‚Äî overall best
  - `top_10.csv` ‚Äî top 10 results

### Analysis Plots
- **Location**: `NeuralNetworks/analysis_plots/`
- **Files**: PNG plots (boxplots, pairplots, correlation matrices, parallel coordinates)

## Analyzing Results

```bash
python analyze_results.py
```

- The script analyzes all training logs from model subfolders, generates plots and CSV reports in `analysis_plots/` and `analysis_results/`.

## Dependencies

Python >= 3.8

Required packages:
- tensorflow == 2.10.0     # core ML framework with Keras API, GPU support
- numpy >= 1.23.0          # vectorized operations and matrix math
- pandas >= 1.5.0          # CSV parsing and data handling
- scikit-learn >= 1.3.0    # preprocessing, metrics, data balancing
- optuna                   # hyperparameter optimization framework
- seaborn                  # statistical data visualization
- matplotlib               # plotting and visualization

Install dependencies:
```bash
pip install -r requirements.txt
```

## Recommended: use a virtual environment to isolate dependencies
```bash
python -m venv .venv
source .venv/bin/activate      # on Unix/Mac
.\.venv\Scripts\activate       # on Windows
```

## GPU Support

The project includes comprehensive GPU support with automatic fallback:

- **CNNOptunaOriginal**: Full GPU support with intelligent parameter filtering and cuDNN compatibility
- **PerceptronOptuna**: Full GPU support
- **RNNOptuna**: Full GPU support with cuDNN for performance

All models automatically detect GPUs, configure memory, and use mixed precision for performance.

## CUDA Diagnostics

For CUDA setup diagnostics, run:

```bash
# Check CUDA version
nvcc --version

# Check GPU devices
python -c "import tensorflow as tf; print('GPU devices:', len(tf.config.list_physical_devices('GPU')))"

# Check CUDA environment variables
echo $env:CUDA_PATH
```

## Example Output

```
Available models:
1. CNNOptunaOriginal
2. PerceptronOptuna
3. RNNOptuna
Enter model numbers separated by ';' or 'all' to run all: 1;2
Selected models: ['CNNOptunaOriginal', 'PerceptronOptuna']

üé• CNN GPU INITIALIZATION
============================================================
üìä Available devices:
   CPU devices: 1
   GPU devices: 1
üéÆ GPU DEVICES DETECTED:
   GPU 0: /physical_device:GPU:0
         Device: NVIDIA GeForce RTX 4060 Ti
         Compute capability: (8, 9)
‚öôÔ∏è  GPU Configuration:
   - Memory growth: ENABLED (dynamic allocation)
   - Mixed precision: ENABLED (for CNN performance)
   - Status: ‚úÖ GPU READY FOR TRAINING

üöÄ Trial 0 - TRAINING START
   Architecture: Input(20,4) ‚Üí Conv1D(10,1) ‚Üí Dense(10) ‚Üí Output(1)
   Hyperparameters: LR=4.11e-03, Batch=32, DropoutConv=0.0, DropoutDense=0.0
   Dataset: 160 train, 40 validation samples
   Device context: /GPU:0
   ‚úÖ Model initialized on: /job:localhost/replica:0/task:0/device:GPU:0 (GPU)
   üìä Model parameters: 46,537
```

## Troubleshooting

### Data Errors
- **"All sequences must have the same length"**: Ensure all sequences in the CSV file have the same length. Use `pad_nucleotides.py` for padding.
- **"FileNotFoundError"**: Check that the TrainData folder exists and contains CSV files.
- **CSV encoding issues**: Save the file in UTF-8 or UTF-8-BOM.

### Model Errors
- **"Invalid units" or unsuitable parameters**: The model may prune unsuitable hyperparameters (TrialPruned). This is normal, Optuna will try others.
- **Model import errors**: Ensure all model files are in correct subfolders and contain the `@register_model` decorator.

### GPU/CUDA Errors
- **"cudnn_ops_infer64_8.dll not found" or similar**: Update NVIDIA drivers, CUDA Toolkit, and cuDNN to versions compatible with TensorFlow 2.10.0. Check the `CUDA_PATH` variable.
- **GPU not detected**: The model will automatically switch to CPU. Check TensorFlow-GPU installation.
- **Out of memory on GPU**: Reduce batch size or disable mixed precision.

### Other Issues
- **Slow performance**: Ensure GPU is being used (check initialization output).

If the problem persists, check console logs and files in `logs/`.

## P.S.

The model training used data from the repository:
https://github.com/BioinformaticsLabAtMUN/BacTermFinder

## License

MIT License
